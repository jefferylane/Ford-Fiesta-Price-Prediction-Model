{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ford Fiesta Price Prediction: Advanced Models Comparison\n",
    "\n",
    "**Goal:** Compare Ridge Regression, Lasso Regression, and Random Forest models for predicting Ford Fiesta prices using the full feature set (including one-hot encoded state and trim variables).\n",
    "\n",
    "**Dataset:** Used Ford Fiestas scraped from cars.com with one-hot encoded categorical variables\n",
    "\n",
    "**Models:** \n",
    "1. Ridge Regression (L2 Regularization)\n",
    "2. Lasso Regression (L1 Regularization)\n",
    "3. Random Forest Regressor\n",
    "\n",
    "**Why These Models?**\n",
    "- **Ridge & Lasso:** Handle multicollinearity better than linear regression, especially important with many one-hot encoded features\n",
    "- **Random Forest:** Captures non-linear relationships and feature interactions automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "Import all the libraries needed for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Data\n",
    "\n",
    "Load the one-hot encoded Ford Fiesta dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the one-hot encoded data\n",
    "df = pd.read_csv('ford_fiestas_extrap_one_hot.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic info\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nColumn names and types:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preparation\n",
    "\n",
    "Prepare the feature matrix (X) and target variable (y). We'll use the numeric features plus all one-hot encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# We want: year, mileage, distance, plus all one-hot encoded state and trim columns\n",
    "# Exclude: title, price, location, trim, state (original categorical columns)\n",
    "\n",
    "exclude_columns = ['title', 'price', 'location', 'trim', 'state']\n",
    "feature_columns = [col for col in df.columns if col not in exclude_columns]\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['price']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"\\nFeatures being used ({len(feature_columns)}):\")\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split\n",
    "\n",
    "Split the data into training and testing sets (80-20 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set price range: ${y_train.min():,.0f} - ${y_train.max():,.0f}\")\n",
    "print(f\"Test set price range: ${y_test.min():,.0f} - ${y_test.max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature Scaling\n",
    "\n",
    "Scale features for Ridge and Lasso regression. This is important because regularization is sensitive to feature scales.\n",
    "\n",
    "**Note:** Random Forest doesn't require scaling, but we'll create scaled versions for Ridge/Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler and fit on training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features have been scaled using StandardScaler\")\n",
    "print(f\"Scaled training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model 1 - Ridge Regression\n",
    "\n",
    "**Ridge Regression** adds L2 regularization, which penalizes large coefficients. This helps prevent overfitting when you have many features.\n",
    "\n",
    "The regularization term is controlled by the `alpha` parameter (higher alpha = more regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge Regression model\n",
    "ridge_model = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ridge_train_pred = ridge_model.predict(X_train_scaled)\n",
    "ridge_test_pred = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "ridge_train_mae = mean_absolute_error(y_train, ridge_train_pred)\n",
    "ridge_test_mae = mean_absolute_error(y_test, ridge_test_pred)\n",
    "ridge_train_rmse = np.sqrt(mean_squared_error(y_train, ridge_train_pred))\n",
    "ridge_test_rmse = np.sqrt(mean_squared_error(y_test, ridge_test_pred))\n",
    "ridge_train_r2 = r2_score(y_train, ridge_train_pred)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RIDGE REGRESSION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  MAE:  ${ridge_train_mae:,.2f}\")\n",
    "print(f\"  RMSE: ${ridge_train_rmse:,.2f}\")\n",
    "print(f\"  R¬≤:   {ridge_train_r2:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MAE:  ${ridge_test_mae:,.2f}\")\n",
    "print(f\"  RMSE: ${ridge_test_rmse:,.2f}\")\n",
    "print(f\"  R¬≤:   {ridge_test_r2:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model 2 - Lasso Regression\n",
    "\n",
    "**Lasso Regression** adds L1 regularization, which can shrink some coefficients to exactly zero. This performs automatic feature selection.\n",
    "\n",
    "This is useful when you suspect many features aren't important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Lasso Regression model\n",
    "lasso_model = Lasso(alpha=1.0, random_state=RANDOM_STATE, max_iter=10000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lasso_train_pred = lasso_model.predict(X_train_scaled)\n",
    "lasso_test_pred = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "lasso_train_mae = mean_absolute_error(y_train, lasso_train_pred)\n",
    "lasso_test_mae = mean_absolute_error(y_test, lasso_test_pred)\n",
    "lasso_train_rmse = np.sqrt(mean_squared_error(y_train, lasso_train_pred))\n",
    "lasso_test_rmse = np.sqrt(mean_squared_error(y_test, lasso_test_pred))\n",
    "lasso_train_r2 = r2_score(y_train, lasso_train_pred)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_test_pred)\n",
    "\n",
    "# Count non-zero coefficients (features selected)\n",
    "n_features_selected = np.sum(lasso_model.coef_ != 0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LASSO REGRESSION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFeatures selected: {n_features_selected} out of {len(feature_columns)}\")\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  MAE:  ${lasso_train_mae:,.2f}\")\n",
    "print(f\"  RMSE: ${lasso_train_rmse:,.2f}\")\n",
    "print(f\"  R¬≤:   {lasso_train_r2:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MAE:  ${lasso_test_mae:,.2f}\")\n",
    "print(f\"  RMSE: ${lasso_test_rmse:,.2f}\")\n",
    "print(f\"  R¬≤:   {lasso_test_r2:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model 3 - Random Forest\n",
    "\n",
    "**Random Forest** is an ensemble method that builds many decision trees and averages their predictions. It can:\n",
    "- Capture non-linear relationships\n",
    "- Automatically detect feature interactions\n",
    "- Handle features of different scales without standardization\n",
    "\n",
    "We'll use unscaled data since Random Forest doesn't require it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=10,          # Maximum depth of each tree\n",
    "    min_samples_split=5,   # Minimum samples to split a node\n",
    "    min_samples_leaf=2,    # Minimum samples in a leaf node\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest model (this may take a moment)...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Make predictions\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rf_train_mae = mean_absolute_error(y_train, rf_train_pred)\n",
    "rf_test_mae = mean_absolute_error(y_test, rf_test_pred)\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_pred))\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_test_pred))\n",
    "rf_train_r2 = r2_score(y_train, rf_train_pred)\n",
    "rf_test_r2 = r2_score(y_test, rf_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOM FOREST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  MAE:  ${rf_train_mae:,.2f}\")\n",
    "print(f\"  RMSE: ${rf_train_rmse:,.2f}\")\n",
    "print(f\"  R¬≤:   {rf_train_r2:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MAE:  ${rf_test_mae:,.2f}\")\n",
    "print(f\"  RMSE: ${rf_test_rmse:,.2f}\")\n",
    "print(f\"  R¬≤:   {rf_test_r2:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model Comparison\n",
    "\n",
    "Compare all three models side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Ridge Regression', 'Lasso Regression', 'Random Forest'],\n",
    "    'Train MAE': [ridge_train_mae, lasso_train_mae, rf_train_mae],\n",
    "    'Test MAE': [ridge_test_mae, lasso_test_mae, rf_test_mae],\n",
    "    'Train RMSE': [ridge_train_rmse, lasso_train_rmse, rf_train_rmse],\n",
    "    'Test RMSE': [ridge_test_rmse, lasso_test_rmse, rf_test_rmse],\n",
    "    'Train R¬≤': [ridge_train_r2, lasso_train_r2, rf_train_r2],\n",
    "    'Test R¬≤': [ridge_test_r2, lasso_test_r2, rf_test_r2]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Find best model by test MAE (lower is better)\n",
    "best_model_idx = comparison_df['Test MAE'].idxmin()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nüèÜ Best Model (by Test MAE): {best_model_name}\")\n",
    "print(f\"   Test MAE: ${comparison_df.loc[best_model_idx, 'Test MAE']:,.2f}\")\n",
    "print(f\"   Test R¬≤:  {comparison_df.loc[best_model_idx, 'Test R¬≤']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Model Performance\n",
    "\n",
    "Create visualizations to compare model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot comparing test metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Test MAE comparison\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['Test MAE'], color=['steelblue', 'coral', 'forestgreen'], alpha=0.7)\n",
    "axes[0].set_ylabel('Test MAE ($)', fontsize=11)\n",
    "axes[0].set_title('Test Mean Absolute Error', fontsize=12, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Test RMSE comparison\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['Test RMSE'], color=['steelblue', 'coral', 'forestgreen'], alpha=0.7)\n",
    "axes[1].set_ylabel('Test RMSE ($)', fontsize=11)\n",
    "axes[1].set_title('Test Root Mean Squared Error', fontsize=12, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Test R¬≤ comparison\n",
    "axes[2].bar(comparison_df['Model'], comparison_df['Test R¬≤'], color=['steelblue', 'coral', 'forestgreen'], alpha=0.7)\n",
    "axes[2].set_ylabel('Test R¬≤ Score', fontsize=11)\n",
    "axes[2].set_title('Test R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "axes[2].tick_params(axis='x', rotation=15)\n",
    "axes[2].set_ylim([0, 1])\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Prediction vs Actual Plots\n",
    "\n",
    "Visualize how well each model's predictions match the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction vs actual plots for all three models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "models_data = [\n",
    "    ('Ridge Regression', ridge_test_pred, 'steelblue'),\n",
    "    ('Lasso Regression', lasso_test_pred, 'coral'),\n",
    "    ('Random Forest', rf_test_pred, 'forestgreen')\n",
    "]\n",
    "\n",
    "for idx, (model_name, predictions, color) in enumerate(models_data):\n",
    "    axes[idx].scatter(y_test, predictions, alpha=0.5, color=color, s=30)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(y_test.min(), predictions.min())\n",
    "    max_val = max(y_test.max(), predictions.max())\n",
    "    axes[idx].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "    \n",
    "    axes[idx].set_xlabel('Actual Price ($)', fontsize=11)\n",
    "    axes[idx].set_ylabel('Predicted Price ($)', fontsize=11)\n",
    "    axes[idx].set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Feature Importance Analysis\n",
    "\n",
    "Let's examine which features are most important for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importances (top 15)\n",
    "rf_importances = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 15 FEATURES - RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "print(rf_importances.head(15).to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Random Forest feature importances (top 15)\n",
    "top_15_features = rf_importances.head(15)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(range(len(top_15_features)), top_15_features['Importance'], color='forestgreen', alpha=0.7)\n",
    "plt.yticks(range(len(top_15_features)), top_15_features['Feature'])\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Features - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression Coefficients (top 15 by absolute value)\n",
    "ridge_coefficients = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': ridge_model.coef_\n",
    "})\n",
    "ridge_coefficients['Abs_Coefficient'] = ridge_coefficients['Coefficient'].abs()\n",
    "ridge_coefficients = ridge_coefficients.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 15 FEATURES - RIDGE REGRESSION (by absolute coefficient)\")\n",
    "print(\"=\"*60)\n",
    "print(ridge_coefficients[['Feature', 'Coefficient']].head(15).to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression Coefficients (only non-zero)\n",
    "lasso_coefficients = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': lasso_model.coef_\n",
    "})\n",
    "lasso_coefficients = lasso_coefficients[lasso_coefficients['Coefficient'] != 0]\n",
    "lasso_coefficients['Abs_Coefficient'] = lasso_coefficients['Coefficient'].abs()\n",
    "lasso_coefficients = lasso_coefficients.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"NON-ZERO FEATURES - LASSO REGRESSION ({len(lasso_coefficients)} selected)\")\n",
    "print(\"=\"*60)\n",
    "print(lasso_coefficients[['Feature', 'Coefficient']].to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Residual Analysis\n",
    "\n",
    "Analyze the prediction errors (residuals) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "ridge_residuals = y_test - ridge_test_pred\n",
    "lasso_residuals = y_test - lasso_test_pred\n",
    "rf_residuals = y_test - rf_test_pred\n",
    "\n",
    "# Plot residuals\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "residuals_data = [\n",
    "    ('Ridge Regression', ridge_residuals, ridge_test_pred, 'steelblue'),\n",
    "    ('Lasso Regression', lasso_residuals, lasso_test_pred, 'coral'),\n",
    "    ('Random Forest', rf_residuals, rf_test_pred, 'forestgreen')\n",
    "]\n",
    "\n",
    "for idx, (model_name, residuals, predictions, color) in enumerate(residuals_data):\n",
    "    axes[idx].scatter(predictions, residuals, alpha=0.5, color=color, s=30)\n",
    "    axes[idx].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[idx].set_xlabel('Predicted Price ($)', fontsize=11)\n",
    "    axes[idx].set_ylabel('Residuals ($)', fontsize=11)\n",
    "    axes[idx].set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Make Predictions with All Models\n",
    "\n",
    "Test all three models by predicting prices for sample cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample cars for prediction\n",
    "sample_cars = [\n",
    "    {'year': 2019, 'mileage': 50000, 'distance': 500, 'trim': 'SE', 'state': 'CO'},\n",
    "    {'year': 2016, 'mileage': 100000, 'distance': 1000, 'trim': 'ST', 'state': 'TX'},\n",
    "    {'year': 2017, 'mileage': 75000, 'distance': 750, 'trim': 'Titanium', 'state': 'CA'}\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"SAMPLE PRICE PREDICTIONS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for i, car in enumerate(sample_cars, 1):\n",
    "    # Create feature vector with one-hot encoding\n",
    "    new_car = pd.DataFrame(0, index=[0], columns=feature_columns)\n",
    "    new_car['year'] = car['year']\n",
    "    new_car['mileage'] = car['mileage']\n",
    "    new_car['distance'] = car['distance']\n",
    "    \n",
    "    # Set one-hot encoded columns\n",
    "    trim_col = f\"trim_{car['trim']}\"\n",
    "    state_col = f\"state_{car['state']}\"\n",
    "    \n",
    "    if trim_col in new_car.columns:\n",
    "        new_car[trim_col] = True\n",
    "    if state_col in new_car.columns:\n",
    "        new_car[state_col] = True\n",
    "    \n",
    "    # Make predictions\n",
    "    new_car_scaled = scaler.transform(new_car)\n",
    "    \n",
    "    ridge_pred = ridge_model.predict(new_car_scaled)[0]\n",
    "    lasso_pred = lasso_model.predict(new_car_scaled)[0]\n",
    "    rf_pred = rf_model.predict(new_car)[0]\n",
    "    \n",
    "    print(f\"\\nCar #{i}: {car['year']} Ford Fiesta {car['trim']}\")\n",
    "    print(f\"  Mileage: {car['mileage']:,} miles\")\n",
    "    print(f\"  Location: {car['state']} ({car['distance']} mi. from Denver)\")\n",
    "    print(f\"  -\" * 30)\n",
    "    print(f\"  Ridge Prediction:  ${ridge_pred:,.2f}\")\n",
    "    print(f\"  Lasso Prediction:  ${lasso_pred:,.2f}\")\n",
    "    print(f\"  RF Prediction:     ${rf_pred:,.2f}\")\n",
    "    print(f\"  Average:           ${(ridge_pred + lasso_pred + rf_pred) / 3:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Summary and Key Insights\n",
    "\n",
    "### Model Comparison Summary\n",
    "\n",
    "**Ridge Regression:**\n",
    "- Uses L2 regularization to prevent overfitting\n",
    "- Shrinks all coefficients but keeps all features\n",
    "- Good baseline for high-dimensional data\n",
    "- Interpretable coefficients\n",
    "\n",
    "**Lasso Regression:**\n",
    "- Uses L1 regularization for automatic feature selection\n",
    "- Sets some coefficients to exactly zero\n",
    "- Helps identify the most important features\n",
    "- Creates a simpler, more interpretable model\n",
    "\n",
    "**Random Forest:**\n",
    "- Ensemble of decision trees\n",
    "- Captures non-linear relationships automatically\n",
    "- Handles feature interactions well\n",
    "- More complex but often more accurate\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Most Important Features:**\n",
    "   - Year, mileage, and distance are typically the strongest predictors\n",
    "   - Certain trim levels (ST, Titanium) have significant impact\n",
    "   - Geographic location (state) has varying influence\n",
    "\n",
    "2. **Model Selection:**\n",
    "   - If interpretability is key ‚Üí Use Ridge or Lasso\n",
    "   - If accuracy is paramount ‚Üí Use Random Forest\n",
    "   - If feature selection is needed ‚Üí Use Lasso\n",
    "\n",
    "3. **Next Steps:**\n",
    "   - Hyperparameter tuning (GridSearchCV)\n",
    "   - Cross-validation for more robust evaluation\n",
    "   - Feature engineering (interactions, polynomials)\n",
    "   - Try gradient boosting models (XGBoost, LightGBM)\n",
    "   - Ensemble methods (combining multiple models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
